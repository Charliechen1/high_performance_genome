{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dataset partitions:  ['dev', '.ipynb_checkpoints', 'train', 'test', 'download.sh']\n"
     ]
    }
   ],
   "source": [
    "data_partitions_dirpath = '../data'\n",
    "print('Available dataset partitions: ', os.listdir(data_partitions_dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset partition \"test\" has 126171 sequences\n",
      "Dataset partition \"dev\" has 126171 sequences\n",
      "Dataset partition \"train\" has 1086741 sequences\n"
     ]
    }
   ],
   "source": [
    "def read_all_shards(partition='dev', data_dir=data_partitions_dirpath):\n",
    "    shards = []\n",
    "    for fn in os.listdir(os.path.join(data_dir, partition)):\n",
    "        with open(os.path.join(data_dir, partition, fn)) as f:\n",
    "            shards.append(pd.read_csv(f, index_col=None))\n",
    "    return pd.concat(shards)\n",
    "\n",
    "test = read_all_shards('test')\n",
    "dev = read_all_shards('dev')\n",
    "train = read_all_shards('train')\n",
    "\n",
    "partitions = {'test': test, 'dev': dev, 'train': train}\n",
    "for name, df in partitions.items():\n",
    "    print('Dataset partition \"%s\" has %d sequences' % (name, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_id</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>family_accession</th>\n",
       "      <th>aligned_sequence</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUF4194</td>\n",
       "      <td>C7MGY1_BRAFD/37-194</td>\n",
       "      <td>PF13835.6</td>\n",
       "      <td>VHLLQGPFLDGRRD...GA.......RYAQLL..RDRTAIEARLAD...</td>\n",
       "      <td>VHLLQGPFLDGRRDGARYAQLLRDRTAIEARLADLFLELIVDDDAQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clathrin_propel</td>\n",
       "      <td>Q7SHV2_NEUCR/257-292</td>\n",
       "      <td>PF01394.20</td>\n",
       "      <td>PPEA.SNDFPVALQVSQKYGIIYL.......ITKYGFIHLYDLE</td>\n",
       "      <td>PPEASNDFPVALQVSQKYGIIYLITKYGFIHLYDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leu_Phe_trans</td>\n",
       "      <td>K7RWT2_ACIA4/30-205</td>\n",
       "      <td>PF03588.14</td>\n",
       "      <td>...VLAALHEGVFPMPIDGDEVPEPLR.GGMGW.....WSPQL......</td>\n",
       "      <td>VLAALHEGVFPMPIDGDEVPEPLRGGMGWWSPQLRARMPLERIRVP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tRNA_anti-codon</td>\n",
       "      <td>EX7L_BACSU/29-104</td>\n",
       "      <td>PF01336.25</td>\n",
       "      <td>IWIK.GELSNVK...............IHT.RGHIYFT.....LKD...</td>\n",
       "      <td>IWIKGELSNVKIHTRGHIYFTLKDENARMQSVMFARQSERLPFKPE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSS-motif</td>\n",
       "      <td>PDED_ECOLI/42-242</td>\n",
       "      <td>PF12792.7</td>\n",
       "      <td>NQQRVVQFANHAVE.ELDKVLLPLQA.G...SEVLLP.LIGLPCS....</td>\n",
       "      <td>NQQRVVQFANHAVEELDKVLLPLQAGSEVLLPLIGLPCSVAHLPLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         family_id         sequence_name family_accession  \\\n",
       "0          DUF4194   C7MGY1_BRAFD/37-194        PF13835.6   \n",
       "1  Clathrin_propel  Q7SHV2_NEUCR/257-292       PF01394.20   \n",
       "2    Leu_Phe_trans   K7RWT2_ACIA4/30-205       PF03588.14   \n",
       "3  tRNA_anti-codon     EX7L_BACSU/29-104       PF01336.25   \n",
       "4        CSS-motif     PDED_ECOLI/42-242        PF12792.7   \n",
       "\n",
       "                                    aligned_sequence  \\\n",
       "0  VHLLQGPFLDGRRD...GA.......RYAQLL..RDRTAIEARLAD...   \n",
       "1       PPEA.SNDFPVALQVSQKYGIIYL.......ITKYGFIHLYDLE   \n",
       "2  ...VLAALHEGVFPMPIDGDEVPEPLR.GGMGW.....WSPQL......   \n",
       "3  IWIK.GELSNVK...............IHT.RGHIYFT.....LKD...   \n",
       "4  NQQRVVQFANHAVE.ELDKVLLPLQA.G...SEVLLP.LIGLPCS....   \n",
       "\n",
       "                                            sequence  \n",
       "0  VHLLQGPFLDGRRDGARYAQLLRDRTAIEARLADLFLELIVDDDAQ...  \n",
       "1               PPEASNDFPVALQVSQKYGIIYLITKYGFIHLYDLE  \n",
       "2  VLAALHEGVFPMPIDGDEVPEPLRGGMGWWSPQLRARMPLERIRVP...  \n",
       "3  IWIKGELSNVKIHTRGHIYFTLKDENARMQSVMFARQSERLPFKPE...  \n",
       "4  NQQRVVQFANHAVEELDKVLLPLQAGSEVLLPLIGLPCSVAHLPLR...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_id</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>family_accession</th>\n",
       "      <th>aligned_sequence</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EKR</td>\n",
       "      <td>R6QAS0_9FIRM/627-685</td>\n",
       "      <td>PF10371.9</td>\n",
       "      <td>.EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFV..DRAD...</td>\n",
       "      <td>EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFVDRADGVY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUF4042</td>\n",
       "      <td>B3MYB3_DROAN/365-542</td>\n",
       "      <td>PF13251.6</td>\n",
       "      <td>KVRISALHLLGSLAKNLPRRFLYGYWHILFPSG.......EHGATN...</td>\n",
       "      <td>KVRISALHLLGSLAKNLPRRFLYGYWHILFPSGEHGATNSHLLLLG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reg_prop</td>\n",
       "      <td>Q8EJN6_SHEON/296-320</td>\n",
       "      <td>PF07494.11</td>\n",
       "      <td>AQANMETLK..AILF...DKSG.LMWVGGSG</td>\n",
       "      <td>AQANMETLKAILFDKSGLMWVGGSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUF3880</td>\n",
       "      <td>M1WYU2_PSEP2/257-334</td>\n",
       "      <td>PF12996.7</td>\n",
       "      <td>WFVDNPHLILHHYTHPGTDNTAIFTYDAGNL.EPLRRKGFANTY.Y...</td>\n",
       "      <td>WFVDNPHLILHHYTHPGTDNTAIFTYDAGNLEPLRRKGFANTYYLP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UPRTase</td>\n",
       "      <td>B6GYG1_PENRW/502-699</td>\n",
       "      <td>PF14681.6</td>\n",
       "      <td>AT.DRPAAKLLMTPMRDASI.SGSALRKVHGRVGFYLATELCT.QI...</td>\n",
       "      <td>ATDRPAAKLLMTPMRDASISGSALRKVHGRVGFYLATELCTQIMGL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  family_id         sequence_name family_accession  \\\n",
       "0       EKR  R6QAS0_9FIRM/627-685        PF10371.9   \n",
       "1   DUF4042  B3MYB3_DROAN/365-542        PF13251.6   \n",
       "2  Reg_prop  Q8EJN6_SHEON/296-320       PF07494.11   \n",
       "3   DUF3880  M1WYU2_PSEP2/257-334        PF12996.7   \n",
       "4   UPRTase  B6GYG1_PENRW/502-699        PF14681.6   \n",
       "\n",
       "                                    aligned_sequence  \\\n",
       "0  .EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFV..DRAD...   \n",
       "1  KVRISALHLLGSLAKNLPRRFLYGYWHILFPSG.......EHGATN...   \n",
       "2                    AQANMETLK..AILF...DKSG.LMWVGGSG   \n",
       "3  WFVDNPHLILHHYTHPGTDNTAIFTYDAGNL.EPLRRKGFANTY.Y...   \n",
       "4  AT.DRPAAKLLMTPMRDASI.SGSALRKVHGRVGFYLATELCT.QI...   \n",
       "\n",
       "                                            sequence  \n",
       "0  EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFVDRADGVY...  \n",
       "1  KVRISALHLLGSLAKNLPRRFLYGYWHILFPSGEHGATNSHLLLLG...  \n",
       "2                          AQANMETLKAILFDKSGLMWVGGSG  \n",
       "3  WFVDNPHLILHHYTHPGTDNTAIFTYDAGNLEPLRRKGFANTYYLP...  \n",
       "4  ATDRPAAKLLMTPMRDASISGSALRKVHGRVGFYLATELCTQIMGL...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'.': 0, 'M': 1, 'H': 2, 'B': 3, 'W': 4, 'R': 5, 'U': 6, \n",
    "         'I': 7, 'O': 8, 'L': 9, 'T': 10, 'D': 11, 'F': 12, 'X': 13, \n",
    "         'Q': 14, 'K': 15, 'N': 16, 'A': 17, 'E': 18, 'Y': 19, \n",
    "         'V': 20, 'Z': 21, 'S': 22, 'P': 23, 'C': 24, 'G': 25}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 0 in training part\n",
      "No 10000 in training part\n",
      "No 20000 in training part\n",
      "No 30000 in training part\n",
      "No 40000 in training part\n",
      "No 50000 in training part\n",
      "No 60000 in training part\n",
      "No 70000 in training part\n",
      "No 80000 in training part\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_raw, X_test_raw = train['aligned_sequence'].values, test['aligned_sequence'].values\n",
    "X_train, X_test = [], []\n",
    "\n",
    "for idx, x in enumerate(X_train_raw):\n",
    "    if idx % 10000 == 0:\n",
    "        print(\"No %d in training part\" % idx)\n",
    "    X_train.append([to_categorical(vocab.get(ch, len(vocab)), len(vocab)) for ch in x])\n",
    "for idx, x in enumerate(X_test_raw):\n",
    "    if idx % 10000 == 0:\n",
    "        print(\"No %d in testing part\" % idx)\n",
    "    X_test.append([to_categorical(vocab.get(ch, len(vocab)), len(vocab)) for ch in x])\n",
    "X_train = np.matrix(X_train)\n",
    "X_test = np.matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = train['aligned_sequence'].values\n",
    "\n",
    "X_train = []\n",
    "\n",
    "max_len = 3000\n",
    "\n",
    "data = np.ones((3000))\n",
    "row_index = np.arange((3000))\n",
    "num = 0\n",
    "for x in X_train_raw:\n",
    "    num += 1\n",
    "    if (num % 100000 == 0):\n",
    "        print(\"No %d in training part\" % num)\n",
    "    length = 0\n",
    "    col_index = []\n",
    "    for char in x:\n",
    "        col_index.append(vocab[char])\n",
    "        length += 1\n",
    "    if (length > 3000):\n",
    "        if (length > max_len):\n",
    "            max_len = length\n",
    "        continue\n",
    "    X_train.append(sparse.coo_matrix((data[:length],(row_index[:length], col_index)), shape=(3000, 26)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 s, sys: 4.61 s, total: 7.38 s\n",
      "Wall time: 7.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train_2 = np.array([x.toarray() for x in X_train])\n",
    "X_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 10000 in training part\n",
      "No 20000 in training part\n",
      "No 30000 in training part\n",
      "No 40000 in training part\n",
      "No 50000 in training part\n",
      "No 60000 in training part\n",
      "No 70000 in training part\n",
      "No 80000 in training part\n",
      "No 90000 in training part\n",
      "No 100000 in training part\n",
      "No 110000 in training part\n",
      "No 120000 in training part\n",
      "No 130000 in training part\n",
      "No 140000 in training part\n",
      "No 150000 in training part\n",
      "No 160000 in training part\n",
      "No 170000 in training part\n",
      "No 180000 in training part\n",
      "No 190000 in training part\n",
      "No 200000 in training part\n",
      "No 210000 in training part\n",
      "No 220000 in training part\n",
      "No 230000 in training part\n",
      "No 240000 in training part\n",
      "No 250000 in training part\n",
      "No 260000 in training part\n",
      "No 270000 in training part\n",
      "No 280000 in training part\n",
      "No 290000 in training part\n",
      "No 300000 in training part\n",
      "No 310000 in training part\n",
      "No 320000 in training part\n",
      "No 330000 in training part\n",
      "No 340000 in training part\n",
      "No 350000 in training part\n",
      "No 360000 in training part\n",
      "No 370000 in training part\n",
      "No 380000 in training part\n",
      "No 390000 in training part\n",
      "No 400000 in training part\n",
      "No 410000 in training part\n",
      "No 420000 in training part\n",
      "No 430000 in training part\n",
      "No 440000 in training part\n",
      "No 450000 in training part\n",
      "No 460000 in training part\n",
      "No 470000 in training part\n",
      "No 480000 in training part\n",
      "No 490000 in training part\n",
      "No 500000 in training part\n",
      "No 510000 in training part\n",
      "No 520000 in training part\n",
      "No 530000 in training part\n",
      "No 540000 in training part\n",
      "No 550000 in training part\n",
      "No 560000 in training part\n",
      "No 570000 in training part\n",
      "No 580000 in training part\n",
      "No 590000 in training part\n",
      "No 600000 in training part\n",
      "No 610000 in training part\n",
      "No 620000 in training part\n",
      "No 630000 in training part\n",
      "No 640000 in training part\n",
      "No 650000 in training part\n",
      "No 660000 in training part\n",
      "No 670000 in training part\n",
      "No 680000 in training part\n",
      "No 690000 in training part\n",
      "No 700000 in training part\n",
      "No 710000 in training part\n",
      "No 720000 in training part\n",
      "No 730000 in training part\n",
      "No 740000 in training part\n",
      "No 750000 in training part\n",
      "No 760000 in training part\n",
      "No 770000 in training part\n",
      "No 780000 in training part\n",
      "No 790000 in training part\n",
      "No 800000 in training part\n",
      "No 810000 in training part\n",
      "No 820000 in training part\n",
      "No 830000 in training part\n",
      "No 840000 in training part\n",
      "No 850000 in training part\n",
      "No 860000 in training part\n",
      "No 870000 in training part\n",
      "No 880000 in training part\n",
      "No 890000 in training part\n",
      "No 900000 in training part\n",
      "No 910000 in training part\n",
      "No 920000 in training part\n",
      "No 930000 in training part\n",
      "No 940000 in training part\n",
      "No 950000 in training part\n",
      "No 960000 in training part\n",
      "No 970000 in training part\n",
      "No 980000 in training part\n",
      "No 990000 in training part\n",
      "No 1000000 in training part\n",
      "No 1010000 in training part\n",
      "No 1020000 in training part\n",
      "No 1030000 in training part\n",
      "No 1040000 in training part\n",
      "No 1050000 in training part\n",
      "No 1060000 in training part\n",
      "No 1070000 in training part\n",
      "No 1080000 in training part\n"
     ]
    }
   ],
   "source": [
    "X_test_raw = test['aligned_sequence'].values\n",
    "\n",
    "X_test = []\n",
    "\n",
    "max_len = 3000\n",
    "\n",
    "data = np.ones((3000))\n",
    "row_index = np.arange((3000))\n",
    "num = 0\n",
    "for x in X_train_raw:\n",
    "    num += 1\n",
    "    if (num % 10000 == 0):\n",
    "        print(\"No %d in test part\" % num)\n",
    "    length = 0\n",
    "    col_index = []\n",
    "    for char in x:\n",
    "        col_index.append(vocab[char])\n",
    "        length += 1\n",
    "    if (length > 3000):\n",
    "        if (length > max_len):\n",
    "            max_len = length\n",
    "        continue\n",
    "    X_test.append(sparse.coo_matrix((data[:length],(row_index[:length], col_index)), shape=(3000, 26)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2866\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw, y_test_raw = train['family_id'].values, test['family_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fam = {fam: idx for idx, fam in enumerate(list(set(y_train_raw)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([all_fam.get(fam, len(all_fam)) for fam in y_train_raw])\n",
    "y_test = np.array([all_fam.get(fam, len(all_fam)) for fam in y_test_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5683, 17625,  4670, ...,  5133, 16801,  2827])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([to_categorical(y, num_classes=len(all_fam) for y in y_train)])\n",
    "y_test = np.array([to_categorical(y, num_classes=len(all_fam) for y in y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../data/preprocess'\n",
    "np.save(outdir + 'X_train', X_train)\n",
    "np.save(outdir + 'X_test', X_test)\n",
    "np.save(outdir + 'y_train', y_train)\n",
    "np.save(outdir + 'y_test', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-intel(cpu)/1.13.1-py36",
   "language": "python",
   "name": "tensorflow_intel_1.13.1_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
