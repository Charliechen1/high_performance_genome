{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import configparser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config/model.conf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"../config/main.conf\"\n",
    "conf = configparser.ConfigParser()\n",
    "conf.read(config_path)\n",
    "\n",
    "model_conf = configparser.ConfigParser()\n",
    "model_conf.read(conf['path']['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dataset partitions:  ['dev', '.ipynb_checkpoints', 'train', 'preprocess', 'test', 'model', 'download.sh']\n"
     ]
    }
   ],
   "source": [
    "data_partitions_dirpath = conf['path']['data_part']\n",
    "print('Available dataset partitions: ', os.listdir(data_partitions_dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset partition \"test\" has 126171 sequences\n",
      "Dataset partition \"dev\" has 126171 sequences\n",
      "Dataset partition \"train\" has 1086741 sequences\n",
      "CPU times: user 6.29 s, sys: 925 ms, total: 7.21 s\n",
      "Wall time: 8.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def read_all_shards(partition='dev', data_dir=data_partitions_dirpath):\n",
    "    shards = []\n",
    "    for fn in os.listdir(os.path.join(data_dir, partition)):\n",
    "        with open(os.path.join(data_dir, partition, fn)) as f:\n",
    "            shards.append(pd.read_csv(f, index_col=None))\n",
    "    return pd.concat(shards)\n",
    "\n",
    "test = read_all_shards('test')\n",
    "dev = read_all_shards('dev')\n",
    "train = read_all_shards('train')\n",
    "\n",
    "partitions = {'test': test, 'dev': dev, 'train': train}\n",
    "for name, df in partitions.items():\n",
    "    print('Dataset partition \"%s\" has %d sequences' % (name, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_id</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>family_accession</th>\n",
       "      <th>aligned_sequence</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUF4194</td>\n",
       "      <td>C7MGY1_BRAFD/37-194</td>\n",
       "      <td>PF13835.6</td>\n",
       "      <td>VHLLQGPFLDGRRD...GA.......RYAQLL..RDRTAIEARLAD...</td>\n",
       "      <td>VHLLQGPFLDGRRDGARYAQLLRDRTAIEARLADLFLELIVDDDAQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clathrin_propel</td>\n",
       "      <td>Q7SHV2_NEUCR/257-292</td>\n",
       "      <td>PF01394.20</td>\n",
       "      <td>PPEA.SNDFPVALQVSQKYGIIYL.......ITKYGFIHLYDLE</td>\n",
       "      <td>PPEASNDFPVALQVSQKYGIIYLITKYGFIHLYDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leu_Phe_trans</td>\n",
       "      <td>K7RWT2_ACIA4/30-205</td>\n",
       "      <td>PF03588.14</td>\n",
       "      <td>...VLAALHEGVFPMPIDGDEVPEPLR.GGMGW.....WSPQL......</td>\n",
       "      <td>VLAALHEGVFPMPIDGDEVPEPLRGGMGWWSPQLRARMPLERIRVP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tRNA_anti-codon</td>\n",
       "      <td>EX7L_BACSU/29-104</td>\n",
       "      <td>PF01336.25</td>\n",
       "      <td>IWIK.GELSNVK...............IHT.RGHIYFT.....LKD...</td>\n",
       "      <td>IWIKGELSNVKIHTRGHIYFTLKDENARMQSVMFARQSERLPFKPE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSS-motif</td>\n",
       "      <td>PDED_ECOLI/42-242</td>\n",
       "      <td>PF12792.7</td>\n",
       "      <td>NQQRVVQFANHAVE.ELDKVLLPLQA.G...SEVLLP.LIGLPCS....</td>\n",
       "      <td>NQQRVVQFANHAVEELDKVLLPLQAGSEVLLPLIGLPCSVAHLPLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         family_id         sequence_name family_accession  \\\n",
       "0          DUF4194   C7MGY1_BRAFD/37-194        PF13835.6   \n",
       "1  Clathrin_propel  Q7SHV2_NEUCR/257-292       PF01394.20   \n",
       "2    Leu_Phe_trans   K7RWT2_ACIA4/30-205       PF03588.14   \n",
       "3  tRNA_anti-codon     EX7L_BACSU/29-104       PF01336.25   \n",
       "4        CSS-motif     PDED_ECOLI/42-242        PF12792.7   \n",
       "\n",
       "                                    aligned_sequence  \\\n",
       "0  VHLLQGPFLDGRRD...GA.......RYAQLL..RDRTAIEARLAD...   \n",
       "1       PPEA.SNDFPVALQVSQKYGIIYL.......ITKYGFIHLYDLE   \n",
       "2  ...VLAALHEGVFPMPIDGDEVPEPLR.GGMGW.....WSPQL......   \n",
       "3  IWIK.GELSNVK...............IHT.RGHIYFT.....LKD...   \n",
       "4  NQQRVVQFANHAVE.ELDKVLLPLQA.G...SEVLLP.LIGLPCS....   \n",
       "\n",
       "                                            sequence  \n",
       "0  VHLLQGPFLDGRRDGARYAQLLRDRTAIEARLADLFLELIVDDDAQ...  \n",
       "1               PPEASNDFPVALQVSQKYGIIYLITKYGFIHLYDLE  \n",
       "2  VLAALHEGVFPMPIDGDEVPEPLRGGMGWWSPQLRARMPLERIRVP...  \n",
       "3  IWIKGELSNVKIHTRGHIYFTLKDENARMQSVMFARQSERLPFKPE...  \n",
       "4  NQQRVVQFANHAVEELDKVLLPLQAGSEVLLPLIGLPCSVAHLPLR...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_id</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>family_accession</th>\n",
       "      <th>aligned_sequence</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EKR</td>\n",
       "      <td>R6QAS0_9FIRM/627-685</td>\n",
       "      <td>PF10371.9</td>\n",
       "      <td>.EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFV..DRAD...</td>\n",
       "      <td>EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFVDRADGVY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUF4042</td>\n",
       "      <td>B3MYB3_DROAN/365-542</td>\n",
       "      <td>PF13251.6</td>\n",
       "      <td>KVRISALHLLGSLAKNLPRRFLYGYWHILFPSG.......EHGATN...</td>\n",
       "      <td>KVRISALHLLGSLAKNLPRRFLYGYWHILFPSGEHGATNSHLLLLG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reg_prop</td>\n",
       "      <td>Q8EJN6_SHEON/296-320</td>\n",
       "      <td>PF07494.11</td>\n",
       "      <td>AQANMETLK..AILF...DKSG.LMWVGGSG</td>\n",
       "      <td>AQANMETLKAILFDKSGLMWVGGSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUF3880</td>\n",
       "      <td>M1WYU2_PSEP2/257-334</td>\n",
       "      <td>PF12996.7</td>\n",
       "      <td>WFVDNPHLILHHYTHPGTDNTAIFTYDAGNL.EPLRRKGFANTY.Y...</td>\n",
       "      <td>WFVDNPHLILHHYTHPGTDNTAIFTYDAGNLEPLRRKGFANTYYLP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UPRTase</td>\n",
       "      <td>B6GYG1_PENRW/502-699</td>\n",
       "      <td>PF14681.6</td>\n",
       "      <td>AT.DRPAAKLLMTPMRDASI.SGSALRKVHGRVGFYLATELCT.QI...</td>\n",
       "      <td>ATDRPAAKLLMTPMRDASISGSALRKVHGRVGFYLATELCTQIMGL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  family_id         sequence_name family_accession  \\\n",
       "0       EKR  R6QAS0_9FIRM/627-685        PF10371.9   \n",
       "1   DUF4042  B3MYB3_DROAN/365-542        PF13251.6   \n",
       "2  Reg_prop  Q8EJN6_SHEON/296-320       PF07494.11   \n",
       "3   DUF3880  M1WYU2_PSEP2/257-334        PF12996.7   \n",
       "4   UPRTase  B6GYG1_PENRW/502-699        PF14681.6   \n",
       "\n",
       "                                    aligned_sequence  \\\n",
       "0  .EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFV..DRAD...   \n",
       "1  KVRISALHLLGSLAKNLPRRFLYGYWHILFPSG.......EHGATN...   \n",
       "2                    AQANMETLK..AILF...DKSG.LMWVGGSG   \n",
       "3  WFVDNPHLILHHYTHPGTDNTAIFTYDAGNL.EPLRRKGFANTY.Y...   \n",
       "4  AT.DRPAAKLLMTPMRDASI.SGSALRKVHGRVGFYLATELCT.QI...   \n",
       "\n",
       "                                            sequence  \n",
       "0  EEKKLVIPTNRPEMKDFVKNILHPIDHLHGDDLPVSKFVDRADGVY...  \n",
       "1  KVRISALHLLGSLAKNLPRRFLYGYWHILFPSGEHGATNSHLLLLG...  \n",
       "2                          AQANMETLKAILFDKSGLMWVGGSG  \n",
       "3  WFVDNPHLILHHYTHPGTDNTAIFTYDAGNLEPLRRKGFANTYYLP...  \n",
       "4  ATDRPAAKLLMTPMRDASISGSALRKVHGRVGFYLATELCTQIMGL...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '.': 1,\n",
       " 'M': 2,\n",
       " 'H': 3,\n",
       " 'B': 4,\n",
       " 'W': 5,\n",
       " 'R': 6,\n",
       " 'U': 7,\n",
       " 'I': 8,\n",
       " 'O': 9,\n",
       " 'L': 10,\n",
       " 'T': 11,\n",
       " 'D': 12,\n",
       " 'F': 13,\n",
       " 'X': 14,\n",
       " 'Q': 15,\n",
       " 'K': 16,\n",
       " 'N': 17,\n",
       " 'A': 18,\n",
       " 'E': 19,\n",
       " 'Y': 20,\n",
       " 'V': 21,\n",
       " 'Z': 22,\n",
       " 'S': 23,\n",
       " 'P': 24,\n",
       " 'C': 25,\n",
       " 'G': 26}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = None\n",
    "vocab_path = conf['path']['vocab']\n",
    "with open(vocab_path, 'r') as of:\n",
    "    vocab = json.load(of)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(x):\n",
    "    \"\"\" converts dense tensor x to sparse format \"\"\"\n",
    "    x_typename = torch.typename(x).split('.')[-1]\n",
    "    sparse_tensortype = getattr(torch.sparse, x_typename)\n",
    "\n",
    "    indices = torch.nonzero(x)\n",
    "    if len(indices.shape) == 0:  # if all elements are zeros\n",
    "        return sparse_tensortype(*x.shape)\n",
    "    indices = indices.t()\n",
    "    values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n",
    "    return sparse_tensortype(indices, values, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(Xs, vocab, max_len):\n",
    "    n_vocab = len(vocab)\n",
    "    for idx, X in enumerate(Xs):\n",
    "        if idx % 10000 == 0:\n",
    "            print(\"Current dealing with data piece no: %s\" % (idx))\n",
    "        tensor = torch.zeros(max_len, n_vocab)\n",
    "        for chidx, ch in enumerate(X[:max_len]):\n",
    "            tensor[chidx][vocab[ch]] = 1\n",
    "        yield to_sparse(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 821 ms, sys: 232 ms, total: 1.05 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "SAMPLE_RATE = 1\n",
    "\n",
    "fams = np.array(train[\"family_id\"].value_counts().index)[::SAMPLE_RATE]\n",
    "partition = train[train[\"family_id\"].isin(fams)]\n",
    "max_len = int(model_conf['Preprocess']['MaxLen'])\n",
    "X = partition['aligned_sequence'].values\n",
    "y = partition['family_id'].values\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.25, random_state=41)\n",
    "fam_vocab = {fam: idx for idx, fam in enumerate(fams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#X_train = make_one_hot(X_train_raw, vocab, max_len)\n",
    "#X_test = make_one_hot(X_test_raw, vocab, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 265 ms, sys: 8.08 ms, total: 274 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#y_train = [y for y in make_one_hot(np.expand_dims(y_train_raw, axis=1), fam_vocab, 1)]\n",
    "#y_test = [y for y in make_one_hot(np.expand_dims(y_test_raw, axis=1), fam_vocab, 1)]\n",
    "y_train = np.array([fam_vocab[y] for y in y_train_raw])\n",
    "y_test = np.array([fam_vocab[y] for y in y_test_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path = {'x_train': '../data/preprocess/x_train',\n",
    "       'x_test': '../data/preprocess/x_test',\n",
    "       'y_train': '../data/preprocess/y_train',\n",
    "       'y_test': '../data/preprocess/y_test'}\n",
    "\n",
    "def store_sparse(x, path):\n",
    "    if os.path.isfile(path):\n",
    "        return\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    torch.save(x.coalesce().values(), path + '/value.pt')\n",
    "    torch.save(x.coalesce().indices(), path + '/indices.pt')\n",
    "    torch.save(x.coalesce().size(), path + '/size.pt')\n",
    "\n",
    "#store_sparse(X_train, path['x_train'])\n",
    "#store_sparse(X_test, path['x_test'])\n",
    "#store_sparse(X_train, path['y_train'])\n",
    "#store_sparse(X_train, path['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, vocab, padding):\n",
    "    res = ['<PAD>'] * padding\n",
    "    res[:min(padding, len(seq))] = seq[:min(padding, len(seq))]\n",
    "    # use 0 for padding\n",
    "    idxs = [vocab[w] for w in res]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def one_hot(label, num_class):\n",
    "    ones = torch.sparse.torch.eye(num_class)\n",
    "    return ones.index_select(0, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, batch_size, padding_idx=0):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
    "        self.dropout_layer = nn.Dropout(p=0.2)\n",
    "        self.batch_size = batch_size\n",
    "        self.padding_idx = padding_idx\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        batch_size, seq_len = X.size()\n",
    "        embeds = self.word_embeddings(X)\n",
    "        lstm_out, _ = self.lstm(embeds.view(batch_size, seq_len, -1))\n",
    "        lstm_out = lstm_out.view(batch_size, seq_len, -1)\n",
    "        # current we just take the last hidden state of the LSTM, later will modify to attention layer\n",
    "        # we do not want to take the state for padding\n",
    "        last_state = lstm_out.mean(1)\n",
    "        tag_space = self.hidden2tag(last_state)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "batch no: 0\n",
      "tensor(9.8021, grad_fn=<NllLossBackward>)\n",
      "batch no: 100\n",
      "tensor(8.9174, grad_fn=<NllLossBackward>)\n",
      "batch no: 200\n",
      "tensor(8.3267, grad_fn=<NllLossBackward>)\n",
      "batch no: 300\n",
      "tensor(8.2890, grad_fn=<NllLossBackward>)\n",
      "batch no: 400\n",
      "tensor(8.0787, grad_fn=<NllLossBackward>)\n",
      "batch no: 500\n",
      "tensor(7.6878, grad_fn=<NllLossBackward>)\n",
      "batch no: 600\n",
      "tensor(7.9445, grad_fn=<NllLossBackward>)\n",
      "batch no: 700\n",
      "tensor(7.4076, grad_fn=<NllLossBackward>)\n",
      "batch no: 800\n",
      "tensor(7.3742, grad_fn=<NllLossBackward>)\n",
      "batch no: 900\n",
      "tensor(7.3807, grad_fn=<NllLossBackward>)\n",
      "batch no: 1000\n",
      "tensor(7.1443, grad_fn=<NllLossBackward>)\n",
      "batch no: 1100\n",
      "tensor(7.0561, grad_fn=<NllLossBackward>)\n",
      "batch no: 1200\n",
      "tensor(7.3944, grad_fn=<NllLossBackward>)\n",
      "batch no: 1300\n",
      "tensor(7.1540, grad_fn=<NllLossBackward>)\n",
      "batch no: 1400\n",
      "tensor(6.5607, grad_fn=<NllLossBackward>)\n",
      "batch no: 1500\n",
      "tensor(7.0277, grad_fn=<NllLossBackward>)\n",
      "batch no: 1600\n",
      "tensor(6.9008, grad_fn=<NllLossBackward>)\n",
      "batch no: 1700\n",
      "tensor(6.3248, grad_fn=<NllLossBackward>)\n",
      "batch no: 1800\n",
      "tensor(6.9107, grad_fn=<NllLossBackward>)\n",
      "batch no: 1900\n",
      "tensor(6.4885, grad_fn=<NllLossBackward>)\n",
      "batch no: 2000\n",
      "tensor(6.4192, grad_fn=<NllLossBackward>)\n",
      "batch no: 2100\n",
      "tensor(6.5337, grad_fn=<NllLossBackward>)\n",
      "batch no: 2200\n",
      "tensor(5.9032, grad_fn=<NllLossBackward>)\n",
      "batch no: 2300\n",
      "tensor(6.1925, grad_fn=<NllLossBackward>)\n",
      "batch no: 2400\n",
      "tensor(6.1400, grad_fn=<NllLossBackward>)\n",
      "batch no: 2500\n",
      "tensor(5.9203, grad_fn=<NllLossBackward>)\n",
      "batch no: 2600\n",
      "tensor(6.0723, grad_fn=<NllLossBackward>)\n",
      "batch no: 2700\n",
      "tensor(5.8149, grad_fn=<NllLossBackward>)\n",
      "batch no: 2800\n",
      "tensor(6.0304, grad_fn=<NllLossBackward>)\n",
      "batch no: 2900\n",
      "tensor(5.8410, grad_fn=<NllLossBackward>)\n",
      "batch no: 3000\n",
      "tensor(5.9159, grad_fn=<NllLossBackward>)\n",
      "batch no: 3100\n",
      "tensor(5.6338, grad_fn=<NllLossBackward>)\n",
      "batch no: 3200\n",
      "tensor(5.7779, grad_fn=<NllLossBackward>)\n",
      "batch no: 3300\n",
      "tensor(5.8980, grad_fn=<NllLossBackward>)\n",
      "batch no: 3400\n",
      "tensor(5.5461, grad_fn=<NllLossBackward>)\n",
      "batch no: 3500\n",
      "tensor(5.6379, grad_fn=<NllLossBackward>)\n",
      "batch no: 3600\n",
      "tensor(5.2818, grad_fn=<NllLossBackward>)\n",
      "batch no: 3700\n",
      "tensor(5.5892, grad_fn=<NllLossBackward>)\n",
      "batch no: 3800\n",
      "tensor(5.3247, grad_fn=<NllLossBackward>)\n",
      "batch no: 3900\n",
      "tensor(6.0011, grad_fn=<NllLossBackward>)\n",
      "batch no: 4000\n",
      "tensor(5.3615, grad_fn=<NllLossBackward>)\n",
      "batch no: 4100\n",
      "tensor(5.1180, grad_fn=<NllLossBackward>)\n",
      "batch no: 4200\n",
      "tensor(5.3349, grad_fn=<NllLossBackward>)\n",
      "batch no: 4300\n",
      "tensor(5.2942, grad_fn=<NllLossBackward>)\n",
      "batch no: 4400\n",
      "tensor(5.1203, grad_fn=<NllLossBackward>)\n",
      "batch no: 4500\n",
      "tensor(5.3741, grad_fn=<NllLossBackward>)\n",
      "batch no: 4600\n",
      "tensor(5.1651, grad_fn=<NllLossBackward>)\n",
      "batch no: 4700\n",
      "tensor(5.1196, grad_fn=<NllLossBackward>)\n",
      "batch no: 4800\n",
      "tensor(5.2724, grad_fn=<NllLossBackward>)\n",
      "batch no: 4900\n",
      "tensor(4.8118, grad_fn=<NllLossBackward>)\n",
      "batch no: 5000\n",
      "tensor(5.3453, grad_fn=<NllLossBackward>)\n",
      "batch no: 5100\n",
      "tensor(4.8174, grad_fn=<NllLossBackward>)\n",
      "batch no: 5200\n",
      "tensor(4.9281, grad_fn=<NllLossBackward>)\n",
      "batch no: 5300\n",
      "tensor(4.9134, grad_fn=<NllLossBackward>)\n",
      "batch no: 5400\n",
      "tensor(4.7777, grad_fn=<NllLossBackward>)\n",
      "batch no: 5500\n",
      "tensor(4.4084, grad_fn=<NllLossBackward>)\n",
      "batch no: 5600\n",
      "tensor(4.6459, grad_fn=<NllLossBackward>)\n",
      "batch no: 5700\n",
      "tensor(4.5016, grad_fn=<NllLossBackward>)\n",
      "batch no: 5800\n",
      "tensor(4.5328, grad_fn=<NllLossBackward>)\n",
      "batch no: 5900\n",
      "tensor(4.8107, grad_fn=<NllLossBackward>)\n",
      "batch no: 6000\n",
      "tensor(4.7289, grad_fn=<NllLossBackward>)\n",
      "batch no: 6100\n",
      "tensor(4.7275, grad_fn=<NllLossBackward>)\n",
      "batch no: 6200\n",
      "tensor(4.4508, grad_fn=<NllLossBackward>)\n",
      "batch no: 6300\n",
      "tensor(4.9369, grad_fn=<NllLossBackward>)\n",
      "epoch: 1\n",
      "batch no: 0\n",
      "tensor(4.5251, grad_fn=<NllLossBackward>)\n",
      "batch no: 100\n",
      "tensor(5.0286, grad_fn=<NllLossBackward>)\n",
      "batch no: 200\n",
      "tensor(4.9384, grad_fn=<NllLossBackward>)\n",
      "batch no: 300\n",
      "tensor(5.0645, grad_fn=<NllLossBackward>)\n",
      "batch no: 400\n",
      "tensor(4.8317, grad_fn=<NllLossBackward>)\n",
      "batch no: 500\n",
      "tensor(4.8213, grad_fn=<NllLossBackward>)\n",
      "batch no: 600\n",
      "tensor(5.7331, grad_fn=<NllLossBackward>)\n",
      "batch no: 700\n",
      "tensor(4.9873, grad_fn=<NllLossBackward>)\n",
      "batch no: 800\n",
      "tensor(5.3346, grad_fn=<NllLossBackward>)\n",
      "batch no: 900\n",
      "tensor(5.8665, grad_fn=<NllLossBackward>)\n",
      "batch no: 1000\n",
      "tensor(5.0357, grad_fn=<NllLossBackward>)\n",
      "batch no: 1100\n",
      "tensor(5.4803, grad_fn=<NllLossBackward>)\n",
      "batch no: 1200\n",
      "tensor(5.5581, grad_fn=<NllLossBackward>)\n",
      "batch no: 1300\n",
      "tensor(5.1064, grad_fn=<NllLossBackward>)\n",
      "batch no: 1400\n",
      "tensor(5.0970, grad_fn=<NllLossBackward>)\n",
      "batch no: 1500\n",
      "tensor(5.5342, grad_fn=<NllLossBackward>)\n",
      "batch no: 1600\n",
      "tensor(5.0814, grad_fn=<NllLossBackward>)\n",
      "batch no: 1700\n",
      "tensor(4.7809, grad_fn=<NllLossBackward>)\n",
      "batch no: 1800\n",
      "tensor(5.0587, grad_fn=<NllLossBackward>)\n",
      "batch no: 1900\n",
      "tensor(5.1189, grad_fn=<NllLossBackward>)\n",
      "batch no: 2000\n",
      "tensor(4.8683, grad_fn=<NllLossBackward>)\n",
      "batch no: 2100\n",
      "tensor(5.2623, grad_fn=<NllLossBackward>)\n",
      "batch no: 2200\n",
      "tensor(4.4885, grad_fn=<NllLossBackward>)\n",
      "batch no: 2300\n",
      "tensor(5.2083, grad_fn=<NllLossBackward>)\n",
      "batch no: 2400\n",
      "tensor(4.9839, grad_fn=<NllLossBackward>)\n",
      "batch no: 2500\n",
      "tensor(4.8310, grad_fn=<NllLossBackward>)\n",
      "batch no: 2600\n",
      "tensor(4.9298, grad_fn=<NllLossBackward>)\n",
      "batch no: 2700\n",
      "tensor(4.9489, grad_fn=<NllLossBackward>)\n",
      "batch no: 2800\n",
      "tensor(5.7875, grad_fn=<NllLossBackward>)\n",
      "batch no: 2900\n",
      "tensor(5.3095, grad_fn=<NllLossBackward>)\n",
      "batch no: 3000\n",
      "tensor(5.3062, grad_fn=<NllLossBackward>)\n",
      "batch no: 3100\n",
      "tensor(4.5873, grad_fn=<NllLossBackward>)\n",
      "batch no: 3200\n",
      "tensor(5.3782, grad_fn=<NllLossBackward>)\n",
      "batch no: 3300\n",
      "tensor(6.6026, grad_fn=<NllLossBackward>)\n",
      "batch no: 3400\n",
      "tensor(9.1544, grad_fn=<NllLossBackward>)\n",
      "batch no: 3500\n",
      "tensor(8.9840, grad_fn=<NllLossBackward>)\n",
      "batch no: 3600\n",
      "tensor(9.0501, grad_fn=<NllLossBackward>)\n",
      "batch no: 3700\n",
      "tensor(9.4142, grad_fn=<NllLossBackward>)\n",
      "batch no: 3800\n",
      "tensor(8.1340, grad_fn=<NllLossBackward>)\n",
      "batch no: 3900\n",
      "tensor(8.7271, grad_fn=<NllLossBackward>)\n",
      "batch no: 4000\n",
      "tensor(8.2742, grad_fn=<NllLossBackward>)\n",
      "batch no: 4100\n",
      "tensor(7.7666, grad_fn=<NllLossBackward>)\n",
      "batch no: 4200\n",
      "tensor(7.6572, grad_fn=<NllLossBackward>)\n",
      "batch no: 4300\n",
      "tensor(8.1155, grad_fn=<NllLossBackward>)\n",
      "batch no: 4400\n",
      "tensor(7.3841, grad_fn=<NllLossBackward>)\n",
      "batch no: 4500\n",
      "tensor(7.6376, grad_fn=<NllLossBackward>)\n",
      "batch no: 4600\n",
      "tensor(7.4837, grad_fn=<NllLossBackward>)\n",
      "batch no: 4700\n",
      "tensor(7.2623, grad_fn=<NllLossBackward>)\n",
      "batch no: 4800\n",
      "tensor(7.5169, grad_fn=<NllLossBackward>)\n",
      "batch no: 4900\n",
      "tensor(7.2874, grad_fn=<NllLossBackward>)\n",
      "batch no: 5000\n",
      "tensor(7.6666, grad_fn=<NllLossBackward>)\n",
      "batch no: 5100\n",
      "tensor(8.1524, grad_fn=<NllLossBackward>)\n",
      "batch no: 5200\n",
      "tensor(7.2009, grad_fn=<NllLossBackward>)\n",
      "batch no: 5300\n",
      "tensor(8.2650, grad_fn=<NllLossBackward>)\n",
      "batch no: 5400\n",
      "tensor(8.0738, grad_fn=<NllLossBackward>)\n",
      "batch no: 5500\n",
      "tensor(7.7337, grad_fn=<NllLossBackward>)\n",
      "batch no: 5600\n",
      "tensor(7.8523, grad_fn=<NllLossBackward>)\n",
      "batch no: 5700\n",
      "tensor(7.4647, grad_fn=<NllLossBackward>)\n",
      "batch no: 6100\n",
      "tensor(10.1064, grad_fn=<NllLossBackward>)\n",
      "batch no: 6200\n",
      "tensor(8.8483, grad_fn=<NllLossBackward>)\n",
      "batch no: 6300\n",
      "tensor(9.8879, grad_fn=<NllLossBackward>)\n",
      "epoch: 2\n",
      "batch no: 0\n",
      "tensor(9.8928, grad_fn=<NllLossBackward>)\n",
      "batch no: 100\n",
      "tensor(10.9922, grad_fn=<NllLossBackward>)\n",
      "batch no: 200\n",
      "tensor(9.9248, grad_fn=<NllLossBackward>)\n",
      "batch no: 300\n",
      "tensor(10.3145, grad_fn=<NllLossBackward>)\n",
      "batch no: 400\n",
      "tensor(10.6800, grad_fn=<NllLossBackward>)\n",
      "batch no: 500\n",
      "tensor(9.7605, grad_fn=<NllLossBackward>)\n",
      "batch no: 600\n",
      "tensor(9.9648, grad_fn=<NllLossBackward>)\n",
      "batch no: 700\n",
      "tensor(9.4521, grad_fn=<NllLossBackward>)\n",
      "batch no: 800\n",
      "tensor(9.3719, grad_fn=<NllLossBackward>)\n",
      "batch no: 900\n",
      "tensor(9.0809, grad_fn=<NllLossBackward>)\n",
      "batch no: 1000\n",
      "tensor(8.3649, grad_fn=<NllLossBackward>)\n",
      "batch no: 1100\n",
      "tensor(9.9364, grad_fn=<NllLossBackward>)\n",
      "batch no: 1200\n",
      "tensor(9.8301, grad_fn=<NllLossBackward>)\n",
      "batch no: 1300\n",
      "tensor(10.4621, grad_fn=<NllLossBackward>)\n",
      "batch no: 1400\n",
      "tensor(9.7160, grad_fn=<NllLossBackward>)\n",
      "batch no: 1500\n",
      "tensor(10.1285, grad_fn=<NllLossBackward>)\n",
      "batch no: 1600\n",
      "tensor(9.3951, grad_fn=<NllLossBackward>)\n",
      "batch no: 1700\n",
      "tensor(9.8279, grad_fn=<NllLossBackward>)\n",
      "batch no: 1800\n",
      "tensor(9.4914, grad_fn=<NllLossBackward>)\n",
      "batch no: 1900\n",
      "tensor(8.9855, grad_fn=<NllLossBackward>)\n",
      "batch no: 2000\n",
      "tensor(9.3871, grad_fn=<NllLossBackward>)\n",
      "batch no: 2100\n",
      "tensor(8.7835, grad_fn=<NllLossBackward>)\n",
      "batch no: 2200\n",
      "tensor(8.9875, grad_fn=<NllLossBackward>)\n",
      "batch no: 2300\n",
      "tensor(8.7169, grad_fn=<NllLossBackward>)\n",
      "batch no: 2400\n",
      "tensor(8.8646, grad_fn=<NllLossBackward>)\n",
      "batch no: 2500\n",
      "tensor(8.3288, grad_fn=<NllLossBackward>)\n",
      "batch no: 2600\n",
      "tensor(9.0816, grad_fn=<NllLossBackward>)\n",
      "batch no: 2700\n",
      "tensor(8.5877, grad_fn=<NllLossBackward>)\n",
      "batch no: 2800\n",
      "tensor(8.8750, grad_fn=<NllLossBackward>)\n",
      "batch no: 2900\n",
      "tensor(8.7021, grad_fn=<NllLossBackward>)\n",
      "batch no: 3000\n",
      "tensor(8.5092, grad_fn=<NllLossBackward>)\n",
      "batch no: 3100\n",
      "tensor(8.8015, grad_fn=<NllLossBackward>)\n",
      "batch no: 3200\n",
      "tensor(9.0942, grad_fn=<NllLossBackward>)\n",
      "batch no: 3300\n",
      "tensor(8.7422, grad_fn=<NllLossBackward>)\n",
      "batch no: 3400\n",
      "tensor(9.0955, grad_fn=<NllLossBackward>)\n",
      "batch no: 3500\n",
      "tensor(8.9210, grad_fn=<NllLossBackward>)\n",
      "batch no: 3600\n",
      "tensor(8.8125, grad_fn=<NllLossBackward>)\n",
      "batch no: 3700\n",
      "tensor(8.5175, grad_fn=<NllLossBackward>)\n",
      "batch no: 3800\n",
      "tensor(8.4940, grad_fn=<NllLossBackward>)\n",
      "batch no: 3900\n",
      "tensor(8.6571, grad_fn=<NllLossBackward>)\n",
      "batch no: 4000\n",
      "tensor(8.5622, grad_fn=<NllLossBackward>)\n",
      "batch no: 4100\n",
      "tensor(8.2600, grad_fn=<NllLossBackward>)\n",
      "batch no: 4400\n",
      "tensor(8.0074, grad_fn=<NllLossBackward>)\n",
      "batch no: 4500\n",
      "tensor(7.7353, grad_fn=<NllLossBackward>)\n",
      "batch no: 4600\n",
      "tensor(8.2129, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBEDDING_DIM = 30\n",
    "HIDDEN_DIM = 20\n",
    "BATCH_SIZE = 128\n",
    "PADDING_SIZE = 300\n",
    "\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(vocab), len(fams), BATCH_SIZE)\n",
    "#loss_function = nn.MSELoss()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "batched_training_data = []\n",
    "loss_track = []\n",
    "# separate data to each batch\n",
    "for idx in range(len(X_train_raw) // BATCH_SIZE + 1):\n",
    "    X_batch = X_train_raw[BATCH_SIZE * idx:BATCH_SIZE * (idx + 1)]\n",
    "    #y_data = [y.to_dense() for y in \n",
    "    #              y_train[BATCH_SIZE * idx:BATCH_SIZE * (idx + 1)]]\n",
    "    y_data = torch.tensor(np.array([y for y in \n",
    "                y_train[BATCH_SIZE * idx:BATCH_SIZE * (idx + 1)]]))\n",
    "    if not len(y_data):\n",
    "        continue\n",
    "    #y_batch = torch.Tensor(len(X_batch), *y_data[0].size())\n",
    "    #torch.cat(y_data, out=y_batch)\n",
    "    #batched_training_data.append((X_batch, y_batch))\n",
    "    batched_training_data.append((X_batch, y_data))\n",
    "\n",
    "model.zero_grad()\n",
    "for epoch in range(10):\n",
    "    print(\"epoch: %d\" % epoch)\n",
    "    idx = 0\n",
    "    for batch, target in batched_training_data:\n",
    "        sentence_batch = [prepare_sequence(sentence, vocab, PADDING_SIZE)\n",
    "                           for sentence in batch]\n",
    "        sentence_in = torch.stack(sentence_batch)\n",
    "        tag_scores = model(sentence_in)\n",
    "        \n",
    "        #labels = torch.max(target, 1)[1]\n",
    "        #loss = loss_function(tag_scores, labels.long())\n",
    "        loss = loss_function(tag_scores, target)\n",
    "        loss_track.append(loss)\n",
    "        if idx % 100 == 0:\n",
    "            #print(\"Sample target:\", labels)\n",
    "            #print(\"Sample outcome:\", torch.max(tag_scores, 1)[1])\n",
    "            print(\"batch no: %d\" % idx)\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        idx += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [prepare_sequence(sentence, vocab, PADDING_SIZE)\n",
    "                           for sentence in X_test_raw]\n",
    "X_test = torch.stack(X_test)\n",
    "score_pred = model(X_test)\n",
    "y_pred = np.array(torch.max(score_pred, 1)[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = np.array([fam_vocab[fam] for fam in y_test_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sum(y_test == y_pred) / len(y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../data/model/10-epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    print(\"epoch: %d\" % epoch)\n",
    "    idx = 0\n",
    "    for batch, target in batched_training_data:\n",
    "        sentence_batch = [prepare_sequence(sentence, vocab, PADDING_SIZE)\n",
    "                           for sentence in batch]\n",
    "        sentence_in = torch.stack(sentence_batch)\n",
    "        tag_scores = model(sentence_in)\n",
    "        \n",
    "        #labels = torch.max(target, 1)[1]\n",
    "        #loss = loss_function(tag_scores, labels.long())\n",
    "        loss = loss_function(tag_scores, target)\n",
    "        if idx % 100 == 0:\n",
    "            #print(\"Sample target:\", labels)\n",
    "            #print(\"Sample outcome:\", torch.max(tag_scores, 1)[1])\n",
    "            print(\"batch no: %d\" % idx)\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(torch.max(score_pred, 1)[1].tolist())\n",
    "y_test = np.array([fam_vocab[fam] for fam in y_test_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sum(y_test == y_pred) / len(y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.2.0 [conda env:root] *",
   "language": "python",
   "name": "conda-root-pytorch-v1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
